---
title: "State of Play: How Australian States Are (Not) Governing AI"
draft: true
date: 2026-01-07
cover:
  image: "cover.jpg"
  alt: "How Australian States Are Governing AI"
  relative: true
ShowToc: false
params:
  description: A survey of NSW, Victoria, Queensland and other states' AI governance frameworks. Some are ahead of the Commonwealth. None are comprehensive.
  images:
  - cover.jpg
  title: "State of Play: How Australian States Are (Not) Governing AI"
tags: ["ai", "governance", "australia", "states", "nsw", "victoria", "queensland", "policy", "auspol"]
---

While the Commonwealth government attracts most attention for its AI policies, state and territory governments are also deploying AI systems, often in areas of significant public impact: education, health, policing, transport, and social services.

Each state has developed its own approach to AI governance. Some are ahead of the Commonwealth. Some are barely engaged. None are comprehensive.

Here's a survey of where things stand.

## New South Wales: The Early Mover

NSW has been the most active Australian jurisdiction on AI governance. Their approach includes:

**The AI Strategy.** [NSW's Artificial Intelligence Strategy](https://www.digital.nsw.gov.au/policy/artificial-intelligence/artificial-intelligence-strategy) sets "the direction on the development and use of AI by NSW Government agencies". It's been in place since 2022, significantly predating the Commonwealth's recent activity.

**Mandatory AI Ethics Policy.** NSW agencies must comply with the [AI Ethics Policy](https://arp.nsw.gov.au/dcs-2024-04-use-of-artificial-intelligence-by-nsw-government-agencies), which requires ethical assessment of AI use cases. This was updated on 1 July 2024.

**AI Assessment Framework.** The [AI Assessment Framework (AIAF)](https://www.digital.nsw.gov.au/policy/artificial-intelligence) provides a structured approach for agencies to evaluate AI risks. It was [updated in July 2024](https://www.digital.nsw.gov.au/policy/artificial-intelligence) to address "new and emerging risks and opportunities".

**AIAF Compliance Plan.** NSW departments must "establish minimum governance and assurance standards" for AI deployments.

**Agentic AI Guide.** NSW has developed an [Agentic AI Guide](https://www.digital.nsw.gov.au/policy/artificial-intelligence), described as "one of the first government guides in the world to focus on this technology", addressing AI systems that take autonomous actions.

This is a more mature governance framework than the Commonwealth's. NSW established mandatory policies before the federal government released its first APS AI Plan. The state has been iterating on its approach for years.

However, NSW's framework shares some limitations with the Commonwealth's:

- It's policy, not legislation. Agencies must comply, but there's no statutory enforcement mechanism.
- Assessment frameworks focus on process compliance, not outcome measurement.
- There's limited public transparency about what AI systems NSW agencies actually deploy.

## Queensland: The Governance Focus

Queensland's approach centres on the [Artificial Intelligence Governance Policy](https://www.forgov.qld.gov.au/information-technology/queensland-government-enterprise-architecture-qgea/qgea-directions-and-guidance/qgea-policies-standards-and-guidelines/artificial-intelligence-governance-policy), issued in September 2024.

The policy "focuses on ensuring agency strategic planning for AI demonstrates a structured and consistent approach when evaluating AI solutions for transparency, accountability, and risk."

Queensland has also issued specific guidance on [Microsoft Copilot](https://www.forgov.qld.gov.au/information-technology/queensland-government-enterprise-architecture-qgea/qgea-directions-and-guidance/qgea-policies-standards-and-guidelines/controlling-data-exposure-copilot-and-copilot-for-m365-guideline), noting that:

> "Data sources accessed by M365 Copilot may contain personal, protected, sensitive, or official information that has been misclassified or secured appropriately. This may lead to the uncontrolled or unauthorised exposure of data."

This is notably more cautious than the Commonwealth's approach to Copilot. Queensland explicitly warns about data exposure risks that the federal Copilot trial also identified.

Queensland's framework is less comprehensive than NSW's, but it demonstrates engagement with specific technical risks rather than just high-level principles.

## Victoria: The Framework Approach

Victoria has adopted the [National Framework for the Assurance of Artificial Intelligence in Government](https://www.vgso.vic.gov.au/prompt-action-new-framework-guide-public-sector-use-ai), released by Australia's Data and Digital Ministers on 21 June 2024.

This framework "sets a governance template for Victorian public sector organisations" and provides:

- A nationally consistent approach to AI adoption
- Guidance on data governance
- A risk-based approach
- Alignment with AI standards (AS ISO/IEC 42001:2023, AS ISO/IEC 23894:2023, AS ISO/IEC 38507:2022)
- Procurement considerations

Victoria's approach is less developed than NSW's in terms of state-specific policies. It's more about adopting national frameworks than developing distinctive governance.

## Other States and Territories

**South Australia** has an [AI Strategy](https://www.dpc.sa.gov.au/digital-government/ai-strategy) that focuses on economic opportunity and innovation rather than governance and risk.

**Western Australia** has limited publicly available AI-specific governance frameworks, though general digital and data governance policies apply.

**Tasmania, ACT, Northern Territory** have minimal AI-specific governance visible in public documentation.

## The Coordination Problem

One of the striking features of Australian AI governance is the lack of coordination between levels of government.

The states are deploying AI in areas that are constitutionally their responsibility: schools, hospitals, police, transport. These deployments aren't covered by Commonwealth governance frameworks.

Meanwhile, citizens interact with both levels of government. A person might receive an AI-influenced decision from Centrelink (Commonwealth) and from their state housing authority (state) in the same week. The governance frameworks, risk tolerances, and transparency requirements may be completely different.

There's no mechanism to ensure that:

- A system deemed too risky for Commonwealth deployment isn't used by states
- Assessment methodologies are consistent across jurisdictions
- Citizens have equivalent rights regardless of which government is using AI on them
- Lessons learned in one jurisdiction are shared with others

The [National Framework](https://www.vgso.vic.gov.au/prompt-action-new-framework-guide-public-sector-use-ai) is a step toward coordination, but it's voluntary and high-level. States can adopt it, adapt it, or ignore it.

## What Happens When Laws Conflict?

Here's a practical problem: the Commonwealth's Privacy Act ADM provisions (commencing December 2026) will impose transparency requirements on federal agencies. But state agencies using AI on the same citizens have no equivalent obligations.

Similarly, if the Commonwealth eventually regulates "high-risk AI" under a mandatory framework, that regulation may not apply to state government AI deployments.

This creates regulatory arbitrage. If the Commonwealth makes AI governance harder, states could become attractive venues for deployment. If states are more permissive, Commonwealth policy objectives are undermined.

The Constitution provides limited solutions. The Commonwealth has power over corporations, trade, and some specific areas, but not general power over state government AI use. Cooperative federalism depends on states choosing to align.

## The Service Delivery Reality

State governments deliver services that are highly consequential for citizens:

- **Education**: Student assessment, resource allocation, learning support decisions
- **Health**: Hospital resource allocation, diagnostic support, treatment recommendations
- **Policing**: Predictive policing, facial recognition, evidence analysis
- **Transport**: Traffic management, public transport scheduling, road safety
- **Child protection**: Risk assessment, case prioritisation, placement decisions
- **Housing**: Eligibility assessment, allocation, waitlist management

In several of these areas, AI is already being deployed. NSW Police has used facial recognition. Victorian child protection has used risk assessment tools. Queensland Health has explored diagnostic support.

The governance frameworks reviewed above may or may not apply to these specific deployments. Documentation is inconsistent. Public transparency is limited.

## Recommendations

For states to develop credible AI governance:

**1. Legislate, don't just policy.** NSW has the most developed framework, but it's still policy, not law. Statutory foundations provide durability and accountability that policies lack.

**2. Require public registers.** Citizens should be able to know what AI systems their state government is using on them. NSW's framework doesn't require public disclosure of deployed systems.

**3. Coordinate with Commonwealth.** The patchwork approach creates gaps and inconsistencies. States should engage with COAG/National Cabinet to develop genuinely national standards.

**4. Address state-specific risks.** Each state has different contexts. Queensland's tropical health challenges differ from Victoria's urban density challenges. AI governance should reflect these differences.

**5. Resource oversight.** Governance frameworks are only as good as their enforcement. States need adequately resourced oversight bodies with real powers.

**6. Engage affected communities.** Many state AI deployments affect vulnerable populations, people in social housing, child protection clients, people interacting with police. These communities should have input into how AI is used on them.

## The Federal-State Gap

The most significant issue may be the gap between federal attention and state action.

The Commonwealth is publishing strategies, establishing institutes, and attracting media coverage. But state governments are quietly deploying AI in schools, hospitals, and police stations without equivalent scrutiny.

When AI governance fails, when a system produces discriminatory outcomes or harmful decisions, the state level may be where it happens. The governance frameworks at state level are less developed, less resourced, and less visible.

This isn't an argument against federal AI governance. It's an argument for recognising that federal action alone is insufficient. The states matter, and right now, most of them aren't governing AI with the seriousness the technology requires.

---

*State AI governance documentation is available through each state's digital government portals. NSW's [Digital.NSW](https://www.digital.nsw.gov.au/policy/artificial-intelligence), Queensland's [ForGov](https://www.forgov.qld.gov.au/information-technology/queensland-government-enterprise-architecture-qgea/qgea-directions-and-guidance/qgea-policies-standards-and-guidelines/artificial-intelligence-governance-policy), and Victoria's [VGSO](https://www.vgso.vic.gov.au/prompt-action-new-framework-guide-public-sector-use-ai) have the most accessible documentation. Other states' frameworks are harder to locate, which is itself revealing.*
