---
title: "Who Guards the Guards? The AI Review Committee's Missing Teeth"
draft: true
date: 2026-01-07
cover:
  image: "cover.jpg"
  alt: "The AI Review Committee's Missing Teeth"
  relative: true
ShowToc: false
params:
  description: The APS AI Plan's "strong governance" rests on an AI Review Committee with no charter, no statutory powers, and no ability to stop harmful deployments.
  images:
  - cover.jpg
  title: "Who Guards the Guards? The AI Review Committee's Missing Teeth"
tags: ["ai", "governance", "australia", "policy", "auspol", "oversight", "accountability", "review committee"]
---

Minister Gallagher's [announcement of the APS AI Plan](https://ministers.finance.gov.au/financeminister/media-release/2025/11/12/whole-government-ai-plan-released) promised "strong governance and transparency". Central to this promise is the AI Review Committee, described as providing "whole-of-government oversight" and "expert advice on higher risk uses of AI".

This sounds reassuring. It's not.

The AI Review Committee has no published charter, no statutory foundation, no enforcement powers, and no ability to halt deployments. It exists at executive discretion and can be disbanded at will. Its advice is explicitly "non-binding".

Compare this to oversight bodies that actually work in Australian government, the OAIC, the Ombudsman, the (former) AAT, and you'll see what's missing: independence, transparency, and teeth.

## What the Committee Actually Is

According to the [APS AI Plan](https://www.digital.gov.au/policy/ai/australian-public-service-ai-plan-2025/what-we-plan-achieve), the AI Review Committee will:

- Be "comprised of APS experts"
- "Ensure consistent, responsible deployment of AI across the APS"
- "Enhance whole-of-government oversight"
- "Provide non-binding advice on sensitive and high-risk AI deployments"
- "Review sensitive cases, offer guidance on emerging risks"

The [DTA is still finalising](https://www.digital.gov.au/policy/ai/australian-public-service-ai-plan-2025/what-we-plan-achieve) the terms of reference. The Committee is scheduled for "December 2025 to December 2026" under the Trust pillar of the plan.

Let's unpack what this means.

## No Statutory Foundation

The AI Review Committee is not established by legislation. It's an administrative body created by executive decision. This has significant consequences:

**No parliamentary oversight.** Unlike statutory bodies, the Committee doesn't report to Parliament. Its operations aren't subject to Senate Estimates questioning in the same way. There's no legislative requirement for annual reports or transparency.

**No independent existence.** The Committee exists at the pleasure of the executive. If a future government (or even the current one) decides the Committee is inconvenient, it can be disbanded without parliamentary approval.

**No defined powers.** Statutory bodies have powers defined in their enabling legislation: the power to investigate, to compel production of documents, to issue binding directions, to impose penalties. The AI Review Committee has none of these by default.

This isn't hypothetical concern. Australia has seen advisory bodies weakened or abolished when their advice became politically inconvenient. The Committee's lack of statutory protection makes it vulnerable.

## "Non-Binding" Means Ignorable

The [plan explicitly states](https://www.digital.gov.au/policy/ai/australian-public-service-ai-plan-2025/what-we-plan-achieve) the Committee provides "non-binding advice". Let's be clear about what this means:

- An agency can receive Committee advice that an AI deployment is high-risk
- The agency can disagree
- The agency can proceed anyway
- There is no mechanism to prevent this

The Committee cannot overrule agency secretaries. It cannot impose penalties for ignoring its advice. It cannot conduct surprise audits or unannounced inspections. It cannot compel agencies to hand over technical documentation.

In governance terms, this is an advisory body, not an oversight body. It can offer opinions. It cannot compel compliance.

## Compare to Bodies That Actually Work

### The OAIC

The [Office of the Australian Information Commissioner](https://www.oaic.gov.au/) is established under the *Australian Information Commissioner Act 2010*. It has:

- **Statutory independence**: The Commissioner can only be removed for specified grounds
- **Investigation powers**: Can investigate complaints, conduct own-motion investigations
- **Enforcement powers**: Can issue enforceable determinations, seek civil penalties
- **Transparency requirements**: Must publish annual reports, appear at Estimates
- **New enhanced powers**: The Privacy Act reforms give it [infringement notice powers and access to a tiered civil penalty regime](https://www.acc.com/litigation-enforcement-ai-and-more-first-tranche-australias-privacy-reforms-explained)

When the OAIC finds a privacy breach, it can do something about it. When the AI Review Committee finds a problematic AI deployment, it can write a memo.

### The Commonwealth Ombudsman

The [Ombudsman](https://www.ombudsman.gov.au/) has statutory powers to:

- Investigate complaints about administrative actions
- Conduct own-motion investigations
- Access agency documents and premises
- Require officials to answer questions
- Make recommendations that, while not binding, carry significant weight due to parliamentary reporting

The Ombudsman can't force agencies to comply, but its recommendations are reported to Parliament. Ignoring them has political consequences. The AI Review Committee has no such accountability pathway.

### The (Former) Administrative Appeals Tribunal

Before its restructuring, the [AAT](https://www.aat.gov.au/) provided merits review of administrative decisions. A citizen affected by a government decision could have it independently reviewed. The AAT could substitute its own decision.

There is no equivalent for AI-related decisions. If an AI system contributes to a harmful outcome, the affected citizen has no specific pathway to have the AI component reviewed. The Committee certainly doesn't provide this.

## What Real Oversight Would Look Like

A credible AI oversight body would have:

**Statutory establishment.** Created by legislation, not executive decision. Requiring parliamentary approval to amend or abolish.

**Independence.** Led by an independent commissioner or board, not "APS experts" who report to the same executives whose decisions they're reviewing.

**Investigation powers.** Ability to conduct own-motion investigations, access agency documents, require officials to answer questions.

**Binding authority.** Power to halt deployments that don't meet standards. Power to require remediation. Meaningful penalties for non-compliance.

**Transparency.** Mandatory public reporting on findings. Parliamentary reporting. Appearance at Senate Estimates.

**Citizen access.** A pathway for affected individuals to seek review of AI-influenced decisions.

**Technical capability.** Resources to actually assess AI systems, not just review agency self-assessments.

The AI Review Committee has none of these features.

## The Timing Problem

The Committee is scheduled for "December 2025 to December 2026". [GovAI is operational from April 2026](https://www.canberratimes.com.au/story/9109838/public-servants-to-have-access-to-govai-chat-under-aps-ai-plan/). [Chief AI Officers must be appointed by July 2026](https://ia.acs.org.au/article/2025/chief-ai-officers-coming-to-australian-govt-agencies.html).

Even if the Committee were well-designed (which it isn't), the timeline ensures it arrives *after* the critical deployment decisions have been made. You don't establish oversight *after* the horse has bolted.

This mirrors the broader pattern in the APS AI Plan: governance arrives after technology, accountability after deployment, oversight after the decisions that matter.

## The "APS Experts" Problem

The Committee is "comprised of APS experts". This creates an inherent conflict:

- APS experts work for agencies
- Agencies are being evaluated by the Committee
- The same executives who approve AI deployments are the bosses of the people reviewing them

This isn't independence. It's self-assessment with extra steps.

Real oversight separates the assessor from the assessed. You don't ask the department that deployed Robodebt to evaluate whether Robodebt was appropriate. You don't ask APS experts to evaluate whether their colleagues' AI deployments meet standards.

## The Precedent Problem

The Committee's design suggests the government expects it to approve things, not stop them. Consider:

- Non-binding advice means agencies can proceed regardless
- No penalty for ignoring advice
- APS composition means aligned interests
- Late establishment means pre-existing deployments grandfathered in

This is a rubber stamp architecture. It creates the appearance of oversight while ensuring oversight doesn't interfere with deployment timelines.

We've seen this before. The ministerial assurances during Robodebt, the committees that reviewed and approved, the layers of "governance" that didn't actually govern. The Royal Commission found that oversight bodies were ineffective because they lacked independence, powers, and willingness to challenge.

The AI Review Committee is designed to repeat these failures.

## What Should Happen

If the government is serious about AI governance:

1. **Establish oversight by legislation.** An AI Commissioner or equivalent, created by statute, with defined independence and powers.

2. **Grant real powers.** Investigation authority. Document access. Ability to halt non-compliant deployments. Meaningful penalties.

3. **Ensure independence.** Leadership appointed by Parliament, not the executive. Protected tenure. Independent budget.

4. **Require transparency.** Mandatory public reporting. Parliamentary accountability. Annual reports that actually describe what's being deployed and what's being found.

5. **Create citizen access.** A pathway for affected individuals to seek review of AI-influenced decisions.

6. **Establish before deployment.** Get oversight operational before GovAI goes live, not a year later.

None of this is happening. Instead, we get an advisory committee with no powers, no independence, and no teeth. It will produce reports that nobody outside the APS reads, make recommendations that agencies can ignore, and provide a veneer of governance that allows ministers to claim they've addressed the risks.

When something goes wrong (and it will), the Committee's existence will be cited as evidence that "appropriate safeguards" were in place. That's its purpose: political cover, not actual oversight.

---

*The terms of reference for the AI Review Committee haven't been published yet. When they are, I'll update this piece. I'm not optimistic they'll address the fundamental problems.*
